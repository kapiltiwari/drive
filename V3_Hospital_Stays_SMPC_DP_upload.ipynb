{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-KKKediaUCt"
      },
      "outputs": [],
      "source": [
        "#mount the data on your google drive\n",
        "#mounting this will help you to call the files from the drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-HdT1_qbIdT"
      },
      "outputs": [],
      "source": [
        "#install all the syft library required\n",
        "#After installed all the library, you have to restart the code again\n",
        "#!pip install 'syft[udacity]'\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afzsu-isciaY"
      },
      "outputs": [],
      "source": [
        "# IMPORT MODULES\n",
        "# TURN ON the GPU !\n",
        "#import all the required libraries\n",
        "\n",
        "import matplotlib\n",
        "import os\n",
        "from operator import itemgetter    \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "get_ipython().magic(u'matplotlib inline')\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import preprocessing\n",
        "#from sklearn.preprocessing import Imputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
        "#from sklearn.cross_validation import KFold, cross_val_score\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, preprocessing\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
        "#from sklearn.utils.fixes import signature\n",
        "#from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "################## need to fix this #######\n",
        "#from mlxtend.plotting import plot_learning_curves\n",
        "#from mlxtend.preprocessing import shuffle_arrays_unison\n",
        "\n",
        "\n",
        "###  need to fix this too.\n",
        "#import tensorflow as tf\n",
        "\n",
        "#from keras import models, regularizers, layers, optimizers, losses, metrics\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n",
        "#from keras.utils import np_utils\n",
        "#from keras.utils import to_categorical\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMkxIlpMV-oF"
      },
      "outputs": [],
      "source": [
        "#!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8C5VrXlc5_Y"
      },
      "outputs": [],
      "source": [
        "#upload the dataset from your device\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBYvwf0ee5hd",
        "outputId": "842c2165-4a6a-47e7-e15a-96d88c209a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With id (58976, 28)\n",
            "No id (58976, 27)\n"
          ]
        }
      ],
      "source": [
        "#call the dataset and data preprocessing\n",
        "data = pd.read_csv('mimic3d.csv')\n",
        "print(\"With id\", data.shape)\n",
        "data_full = data.drop('hadm_id', 1)\n",
        "print(\"No id\",data_full.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4qxeEWTe-9d",
        "outputId": "4dd0caba-e903-42c4-cfec-2bca25f1462e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y - Labels (58976,)\n",
            "X - No Label No id  (58976, 18)\n",
            "Index(['gender', 'age', 'admit_type', 'admit_location', 'NumCallouts',\n",
            "       'NumDiagnosis', 'NumProcs', 'NumCPTevents', 'NumInput', 'NumLabs',\n",
            "       'NumMicroLabs', 'NumNotes', 'NumOutput', 'NumRx', 'NumProcEvents',\n",
            "       'NumTransfers', 'NumChartEvents', 'TotalNumInteract'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Label = LOS\n",
        "#data preprocessing\n",
        "\n",
        "y = data_full['LOSgroupNum']\n",
        "X = data_full.drop('LOSgroupNum', 1)\n",
        "X = X.drop('LOSdays', 1)\n",
        "X = X.drop('ExpiredHospital', 1)\n",
        "X = X.drop('AdmitDiagnosis', 1)\n",
        "X = X.drop('AdmitProcedure', 1)\n",
        "X = X.drop('marital_status', 1)\n",
        "X = X.drop('ethnicity', 1)\n",
        "X = X.drop('religion', 1)\n",
        "X = X.drop('insurance', 1)\n",
        "\n",
        "print(\"y - Labels\", y.shape)\n",
        "print(\"X - No Label No id \", X.shape)\n",
        "print(X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFBemIEwfEmz",
        "outputId": "456751a7-dee0-4a5c-ff26-561de6f8b28a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(58976, 18)\n",
            "(58976, 30)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "categorical_columns = [\n",
        "                    'gender',                     \n",
        "                    'admit_type',\n",
        "                    'admit_location'\n",
        "                      ]\n",
        "\n",
        "for col in categorical_columns:\n",
        "    #if the original column is present replace it with a one-hot\n",
        "    if col in X.columns:\n",
        "        one_hot_encoded = pd.get_dummies(X[col])\n",
        "        X = X.drop(col, axis=1)\n",
        "        X = X.join(one_hot_encoded, lsuffix='_left', rsuffix='_right')\n",
        "        \n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGOaDn3efPzP",
        "outputId": "a1788563-24ba-4e39-b349-3323c14ef723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(58976, 27)\n",
            "(58976, 30)\n",
            "XnotNorm  (58976, 30)\n",
            "ynotNorm  (58976,)\n"
          ]
        }
      ],
      "source": [
        "print(data_full.shape)\n",
        "print(X.shape)\n",
        "#XnotNorm = np.array(X.copy())\n",
        "XnotNorm = X.copy()\n",
        "print('XnotNorm ', XnotNorm.shape)\n",
        "\n",
        "ynotNorm = y.copy()\n",
        "print('ynotNorm ', ynotNorm.shape)   #data normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf3WXstkfUZz",
        "outputId": "5c5dda8e-9a07-4e09-dd67-3cfec04096a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            age  NumCallouts  NumDiagnosis  NumProcs  NumCPTevents  NumInput  \\\n",
            "0     -0.691792     0.370949     -0.010400 -0.220794      0.111429 -0.084239   \n",
            "1      0.230296     0.921627     -0.053954  0.057447      0.446879 -0.268607   \n",
            "2     -0.192328    -0.608032     -0.233011 -0.173015     -0.120425 -0.303045   \n",
            "3      0.768180     1.900608     -0.240270 -0.144910     -0.189488 -0.161446   \n",
            "4      0.268716    -0.608032      0.122683  0.009668      0.580072 -0.158403   \n",
            "...         ...          ...           ...       ...           ...       ...   \n",
            "58971  0.268716    -0.608032     -0.278985 -0.071837     -0.066161  4.814076   \n",
            "58972  0.191876    -0.608032     -0.212444 -0.105563     -0.224020  1.037984   \n",
            "58973 -1.152835    -0.608032     -0.251159 -0.069026     -0.500273 -0.283824   \n",
            "58974  0.614499    -0.608032      0.005328 -0.077458     -0.446009 -0.072546   \n",
            "58975  1.344485    -0.608032     -0.038226 -0.170205      0.096630 -0.378811   \n",
            "\n",
            "        NumLabs  NumMicroLabs  NumNotes  NumOutput  ...    URGENT  \\\n",
            "0     -0.039194     -0.134520 -0.060115  -0.254456  ... -0.152244   \n",
            "1      0.125148      0.004741 -0.045683  -0.220027  ... -0.152244   \n",
            "2     -0.171325     -0.210051 -0.059178  -0.392173  ... -0.152244   \n",
            "3     -0.186444     -0.125078 -0.058990   0.256683  ... -0.152244   \n",
            "4      0.055073     -0.143961 -0.057397   1.202158  ... -0.152244   \n",
            "...         ...           ...       ...        ...  ...       ...   \n",
            "58971  0.264773     -0.240735 -0.059365   2.118501  ... -0.152244   \n",
            "58972  0.086889      0.245497 -0.057772   0.104400  ... -0.152244   \n",
            "58973 -0.251655     -0.160483 -0.059646  -0.111443  ... -0.152244   \n",
            "58974  0.044818     -0.247816 -0.057303   0.679101  ... -0.152244   \n",
            "58975 -0.086787      0.099155 -0.056835  -0.315369  ... -0.152244   \n",
            "\n",
            "       ** INFO NOT AVAILABLE **  CLINIC REFERRAL/PREMATURE  \\\n",
            "0                     -0.058916                   1.975246   \n",
            "1                     -0.058916                  -0.506266   \n",
            "2                     -0.058916                  -0.506266   \n",
            "3                     -0.058916                  -0.506266   \n",
            "4                     -0.058916                  -0.506266   \n",
            "...                         ...                        ...   \n",
            "58971                 -0.058916                  -0.506266   \n",
            "58972                 -0.058916                  -0.506266   \n",
            "58973                 -0.058916                  -0.506266   \n",
            "58974                 -0.058916                  -0.506266   \n",
            "58975                 -0.058916                   1.975246   \n",
            "\n",
            "       EMERGENCY ROOM ADMIT  HMO REFERRAL/SICK  PHYS REFERRAL/NORMAL DELI  \\\n",
            "0                 -0.792579          -0.041623                  -0.586096   \n",
            "1                  1.261704          -0.041623                  -0.586096   \n",
            "2                  1.261704          -0.041623                  -0.586096   \n",
            "3                  1.261704          -0.041623                  -0.586096   \n",
            "4                 -0.792579          -0.041623                  -0.586096   \n",
            "...                     ...                ...                        ...   \n",
            "58971             -0.792579          -0.041623                  -0.586096   \n",
            "58972              1.261704          -0.041623                  -0.586096   \n",
            "58973             -0.792579          -0.041623                   1.706205   \n",
            "58974             -0.792579          -0.041623                  -0.586096   \n",
            "58975             -0.792579          -0.041623                  -0.586096   \n",
            "\n",
            "       TRANSFER FROM HOSP/EXTRAM  TRANSFER FROM OTHER HEALT  \\\n",
            "0                       -0.40912                  -0.034718   \n",
            "1                       -0.40912                  -0.034718   \n",
            "2                       -0.40912                  -0.034718   \n",
            "3                       -0.40912                  -0.034718   \n",
            "4                        2.44427                  -0.034718   \n",
            "...                          ...                        ...   \n",
            "58971                    2.44427                  -0.034718   \n",
            "58972                   -0.40912                  -0.034718   \n",
            "58973                   -0.40912                  -0.034718   \n",
            "58974                    2.44427                  -0.034718   \n",
            "58975                   -0.40912                  -0.034718   \n",
            "\n",
            "       TRANSFER FROM SKILLED NUR  TRSF WITHIN THIS FACILITY  \n",
            "0                      -0.068195                  -0.009208  \n",
            "1                      -0.068195                  -0.009208  \n",
            "2                      -0.068195                  -0.009208  \n",
            "3                      -0.068195                  -0.009208  \n",
            "4                      -0.068195                  -0.009208  \n",
            "...                          ...                        ...  \n",
            "58971                  -0.068195                  -0.009208  \n",
            "58972                  -0.068195                  -0.009208  \n",
            "58973                  -0.068195                  -0.009208  \n",
            "58974                  -0.068195                  -0.009208  \n",
            "58975                  -0.068195                  -0.009208  \n",
            "\n",
            "[58976 rows x 30 columns]\n",
            "X normalized\n"
          ]
        }
      ],
      "source": [
        "# Normalize X\n",
        "\n",
        "x = XnotNorm.values #returns a numpy array\n",
        "scaler = preprocessing.StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "XNorm = pd.DataFrame(x_scaled, columns=XnotNorm.columns)\n",
        "print(XNorm)\n",
        "#print(y)\n",
        "print('X normalized')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npd3YyDpfYYG",
        "outputId": "757e38a8-f769-4209-bd41-e39c9464fcaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train:  (58386, 30)\n",
            "X_test:  (590, 30)\n",
            "y_train:  (58386,)\n",
            "y_test:  (590,)\n"
          ]
        }
      ],
      "source": [
        "# SPLIT data into Train & Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.01, random_state=7)\n",
        "#X_train=XNorm[0:58386]\n",
        "#y_train=y[0:58386]\n",
        "#X_test=XNorm[58386:58386+590]\n",
        "#y_test=y[58386:58386+590]\n",
        "print ('X_train: ', X_train.shape)\n",
        "print ('X_test: ', X_test.shape)\n",
        "print ('y_train: ', y_train.shape)\n",
        "print ('y_test: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW9cM7tDpOCx"
      },
      "outputs": [],
      "source": [
        "#categorical of y_data\n",
        "y_test=y_test.values.tolist()\n",
        "y_train=y_train.values.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk23ALxjbulD"
      },
      "outputs": [],
      "source": [
        "X_train=pd.DataFrame(X_train).to_numpy()\n",
        "#y_train=pd.DataFrame(y_train).to_numpy()\n",
        "X_test=pd.DataFrame(X_test).to_numpy()\n",
        "#y_test=pd.DataFrame(y_test).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIeP9VUWfcFg",
        "outputId": "042cec31-8be5-4c2f-d246-04bffb244bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(29193, 30)\n"
          ]
        }
      ],
      "source": [
        "#devide the data into m model owners\n",
        "import numpy as np\n",
        "\n",
        "j=0\n",
        "M=2  #number of model owners=10\n",
        "number=len(X_train)\n",
        "k=number/M\n",
        "#print(x_train)\n",
        "\n",
        "for x in range(0,M):\n",
        "             globals()['x_train_split%s' % x]=X_train[int(j):int(k+j)]\n",
        "             globals()['y_train_split%s' % x]=y_train[int(j):int(k+j)]\n",
        "             j=j+k\n",
        "print(x_train_split0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04F2dpEteFlA"
      },
      "outputs": [],
      "source": [
        "#take 500 test data from all test datasets\n",
        "x_test=X_test[0:500]\n",
        "y_test=y_test[0:500]\n",
        "#y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqTrKydShOh1"
      },
      "outputs": [],
      "source": [
        "#import all the torch libraries as we are going to use pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lstUiQAZhWmr"
      },
      "outputs": [],
      "source": [
        "#initialize required parameters\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yksjNqqWhaP_"
      },
      "outputs": [],
      "source": [
        "#import the syft libraries\n",
        "#create two virtual workers and one crypto_provider\n",
        "#import syft as sy\n",
        "#hook = sy.TorchHook(torch) \n",
        "#client = sy.VirtualWorker(hook, id=\"client\")\n",
        "#bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "#alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "#crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")\n",
        "\n",
        "\n",
        "## new impl\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "import sympc\n",
        "from sympc.session import Session\n",
        "from sympc.session import SessionManager\n",
        "from sympc.tensor import MPCTensor\n",
        "\n",
        "\n",
        "# Define the virtual machines that would be use in the computation\n",
        "alice_vm = sy.VirtualMachine(name=\"alice\")\n",
        "bob_vm = sy.VirtualMachine(name=\"bob\")\n",
        "crypto_provider_vm = sy.VirtualMachine(name=\"crypto_provider\")\n",
        "\n",
        "# Get clients from each VM\n",
        "alice = alice_vm.get_root_client()\n",
        "bob = bob_vm.get_root_client()\n",
        "crypto_provider = crypto_provider_vm.get_root_client()\n",
        "\n",
        "parties = [alice, bob]\n",
        "\n",
        "#Setup the session for the computation\n",
        "session = Session(parties=parties)\n",
        "SessionManager.setup_mpc(session)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMH4Hh_JhfbZ"
      },
      "outputs": [],
      "source": [
        "epochs = 10  #number of epoches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIKmXhmyhiCO"
      },
      "outputs": [],
      "source": [
        "#argument function\n",
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 50\n",
        "        self.epochs = epochs\n",
        "        self.lr = 0.001\n",
        "        self.log_interval = 100\n",
        "\n",
        "args = Arguments()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKrgoAZXhlq0"
      },
      "outputs": [],
      "source": [
        "#transform all numpy train vectors into torch tensor\n",
        "for i in range(0,M):\n",
        "     globals()['tensor_x%s' % i] =torch.Tensor(globals()['x_train_split%s' % i]) # transform to torch tensor\n",
        "     globals()['tensor_y%s' % i] = torch.Tensor(globals()['y_train_split%s' % i])\n",
        "     globals()['tensor_y%s' % i]=globals()['tensor_y%s' % i].type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a6SeyGwiqA1"
      },
      "outputs": [],
      "source": [
        "#transform test vectors into torch tensor\n",
        "test_x=torch.Tensor(x_test)\n",
        "test_y=torch.Tensor(y_test)\n",
        "#tensor_x=tensor_x.type(torch.LongTensor)\n",
        "#test_x=test_x.type(torch.LongTensor)\n",
        "test_y=test_y.type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyI_ULQQi-2k"
      },
      "outputs": [],
      "source": [
        "for iter in range(0,M):\n",
        "  globals()['my_dataset%s' % iter] = TensorDataset(globals()['tensor_x%s' % iter],globals()['tensor_y%s' % iter]) \n",
        "  globals()['train_loader%s' % iter] = DataLoader(globals()['my_dataset%s' % iter],batch_size=args.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohZR4cvZjDjv"
      },
      "outputs": [],
      "source": [
        "#create test dataset\n",
        "test_datasets=TensorDataset(test_x,test_y) \n",
        "test_case_loader=DataLoader(test_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkenM1bUjGco"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_datasets,batch_size=args.test_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYJGE6Du9wUA",
        "outputId": "51b9d815-2abe-4c2a-8fdd-0a3fa0dfb57e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.1000, -1.0000],\n",
            "        [-4.0000,  4.0000]])\n",
            "tensor([[ 4.0000, -2.5000],\n",
            "        [ 5.0000,  2.0000]])\n",
            "[MPCTensor]\n",
            "Shape: torch.Size([2, 2])\n",
            "Requires Grad: False\n",
            "\t| <VirtualMachineClient: alice Client> -> ShareTensorPointer\n",
            "\t| <VirtualMachineClient: bob Client> -> ShareTensorPointer\n",
            "[MPCTensor]\n",
            "Shape: torch.Size([2, 2])\n",
            "Requires Grad: False\n",
            "\t| <VirtualMachineClient: alice Client> -> ShareTensorPointer\n",
            "\t| <VirtualMachineClient: bob Client> -> ShareTensorPointer\n"
          ]
        }
      ],
      "source": [
        "# TBD\n",
        "# Define the private values to shares\n",
        "x_secret = torch.Tensor([[0.1, -1], [-4, 4]])\n",
        "y_secret = torch.Tensor([[4.0, -2.5], [5, 2]])\n",
        "\n",
        "print(x_secret)\n",
        "print(y_secret)\n",
        "\n",
        "# 1. Share the secret between some members of the session\n",
        "x = x_secret.share(parties=[alice, bob])\n",
        "y = y_secret.share(parties=[alice, bob])\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr-kxJkpjL4i"
      },
      "outputs": [],
      "source": [
        "#create private test loader where client secretly shared their data to worker1 and worker2\n",
        "private_test_loader = []\n",
        "for data, target in test_loader:\n",
        "    private_test_loader.append((\n",
        "        data.share(parties=[alice, bob, crypto_provider]),\n",
        "        target.share(parties=[alice, bob, crypto_provider])\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg2Swf6_jNaD"
      },
      "outputs": [],
      "source": [
        "#create private test loader where client secretly shared their data to worker1 and worker2\n",
        "private_new_loader = []\n",
        "for data, target in test_case_loader:\n",
        "    private_new_loader.append((\n",
        "        data.share(session=session),\n",
        "        #target.share(parties=[alice, bob, crypto_provider])\n",
        "        target.share(session=session)\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aC9nuMbjRkB"
      },
      "outputs": [],
      "source": [
        "#Feed forward Neural Network\n",
        "class Net(sy.Module):\n",
        "    def __init__(self, torch_ref):\n",
        "        super(Net, self).__init__(torch_ref=torch_ref)\n",
        "        self.fc1 = self.torch_ref.nn.Linear(30, 500)\n",
        "        self.fc2 = self.torch_ref.nn.Linear(500, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 30)\n",
        "        x = self.fc1(x)\n",
        "        #x = F.relu(x)\n",
        "        x = self.torch_ref.nn.functional.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhuBSuQ4jVLT"
      },
      "outputs": [],
      "source": [
        "#training is local training so no encryption \n",
        "def train(args, model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7yW3c4yjZJt",
        "outputId": "c63c4174-2156-426f-d4b4-c7466eb4f189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/29248 (0%)]\tLoss: 1.406744\n",
            "Train Epoch: 1 [6400/29248 (22%)]\tLoss: 1.053908\n",
            "Train Epoch: 1 [12800/29248 (44%)]\tLoss: 0.792262\n",
            "Train Epoch: 1 [19200/29248 (66%)]\tLoss: 0.694622\n",
            "Train Epoch: 1 [25600/29248 (88%)]\tLoss: 0.711838\n",
            "Train Epoch: 2 [0/29248 (0%)]\tLoss: 0.603390\n",
            "Train Epoch: 2 [6400/29248 (22%)]\tLoss: 0.628273\n",
            "Train Epoch: 2 [12800/29248 (44%)]\tLoss: 0.532505\n",
            "Train Epoch: 2 [19200/29248 (66%)]\tLoss: 0.570031\n",
            "Train Epoch: 2 [25600/29248 (88%)]\tLoss: 0.681208\n",
            "Train Epoch: 3 [0/29248 (0%)]\tLoss: 0.534630\n",
            "Train Epoch: 3 [6400/29248 (22%)]\tLoss: 0.535583\n",
            "Train Epoch: 3 [12800/29248 (44%)]\tLoss: 0.492010\n",
            "Train Epoch: 3 [19200/29248 (66%)]\tLoss: 0.526558\n",
            "Train Epoch: 3 [25600/29248 (88%)]\tLoss: 0.663677\n",
            "Train Epoch: 4 [0/29248 (0%)]\tLoss: 0.521288\n",
            "Train Epoch: 4 [6400/29248 (22%)]\tLoss: 0.492757\n",
            "Train Epoch: 4 [12800/29248 (44%)]\tLoss: 0.477426\n",
            "Train Epoch: 4 [19200/29248 (66%)]\tLoss: 0.503135\n",
            "Train Epoch: 4 [25600/29248 (88%)]\tLoss: 0.642961\n",
            "Train Epoch: 5 [0/29248 (0%)]\tLoss: 0.514731\n",
            "Train Epoch: 5 [6400/29248 (22%)]\tLoss: 0.469013\n",
            "Train Epoch: 5 [12800/29248 (44%)]\tLoss: 0.468375\n",
            "Train Epoch: 5 [19200/29248 (66%)]\tLoss: 0.485390\n",
            "Train Epoch: 5 [25600/29248 (88%)]\tLoss: 0.629031\n",
            "Train Epoch: 6 [0/29248 (0%)]\tLoss: 0.506951\n",
            "Train Epoch: 6 [6400/29248 (22%)]\tLoss: 0.453050\n",
            "Train Epoch: 6 [12800/29248 (44%)]\tLoss: 0.461752\n",
            "Train Epoch: 6 [19200/29248 (66%)]\tLoss: 0.468209\n",
            "Train Epoch: 6 [25600/29248 (88%)]\tLoss: 0.613908\n",
            "Train Epoch: 7 [0/29248 (0%)]\tLoss: 0.504886\n",
            "Train Epoch: 7 [6400/29248 (22%)]\tLoss: 0.444443\n",
            "Train Epoch: 7 [12800/29248 (44%)]\tLoss: 0.456986\n",
            "Train Epoch: 7 [19200/29248 (66%)]\tLoss: 0.454254\n",
            "Train Epoch: 7 [25600/29248 (88%)]\tLoss: 0.598296\n",
            "Train Epoch: 8 [0/29248 (0%)]\tLoss: 0.493980\n",
            "Train Epoch: 8 [6400/29248 (22%)]\tLoss: 0.434403\n",
            "Train Epoch: 8 [12800/29248 (44%)]\tLoss: 0.448966\n",
            "Train Epoch: 8 [19200/29248 (66%)]\tLoss: 0.439394\n",
            "Train Epoch: 8 [25600/29248 (88%)]\tLoss: 0.584985\n",
            "Train Epoch: 9 [0/29248 (0%)]\tLoss: 0.495649\n",
            "Train Epoch: 9 [6400/29248 (22%)]\tLoss: 0.426731\n",
            "Train Epoch: 9 [12800/29248 (44%)]\tLoss: 0.445962\n",
            "Train Epoch: 9 [19200/29248 (66%)]\tLoss: 0.425847\n",
            "Train Epoch: 9 [25600/29248 (88%)]\tLoss: 0.569848\n",
            "Train Epoch: 10 [0/29248 (0%)]\tLoss: 0.482460\n",
            "Train Epoch: 10 [6400/29248 (22%)]\tLoss: 0.418436\n",
            "Train Epoch: 10 [12800/29248 (44%)]\tLoss: 0.437810\n",
            "Train Epoch: 10 [19200/29248 (66%)]\tLoss: 0.412097\n",
            "Train Epoch: 10 [25600/29248 (88%)]\tLoss: 0.558648\n",
            "Train Epoch: 1 [0/29248 (0%)]\tLoss: 1.412708\n",
            "Train Epoch: 1 [6400/29248 (22%)]\tLoss: 0.978170\n",
            "Train Epoch: 1 [12800/29248 (44%)]\tLoss: 0.872748\n",
            "Train Epoch: 1 [19200/29248 (66%)]\tLoss: 0.747653\n",
            "Train Epoch: 1 [25600/29248 (88%)]\tLoss: 0.840502\n",
            "Train Epoch: 2 [0/29248 (0%)]\tLoss: 0.690729\n",
            "Train Epoch: 2 [6400/29248 (22%)]\tLoss: 0.602699\n",
            "Train Epoch: 2 [12800/29248 (44%)]\tLoss: 0.560288\n",
            "Train Epoch: 2 [19200/29248 (66%)]\tLoss: 0.584717\n",
            "Train Epoch: 2 [25600/29248 (88%)]\tLoss: 0.763218\n",
            "Train Epoch: 3 [0/29248 (0%)]\tLoss: 0.664092\n",
            "Train Epoch: 3 [6400/29248 (22%)]\tLoss: 0.534877\n",
            "Train Epoch: 3 [12800/29248 (44%)]\tLoss: 0.511339\n",
            "Train Epoch: 3 [19200/29248 (66%)]\tLoss: 0.541161\n",
            "Train Epoch: 3 [25600/29248 (88%)]\tLoss: 0.751187\n",
            "Train Epoch: 4 [0/29248 (0%)]\tLoss: 0.667288\n",
            "Train Epoch: 4 [6400/29248 (22%)]\tLoss: 0.517780\n",
            "Train Epoch: 4 [12800/29248 (44%)]\tLoss: 0.496032\n",
            "Train Epoch: 4 [19200/29248 (66%)]\tLoss: 0.525395\n",
            "Train Epoch: 4 [25600/29248 (88%)]\tLoss: 0.747330\n",
            "Train Epoch: 5 [0/29248 (0%)]\tLoss: 0.666871\n",
            "Train Epoch: 5 [6400/29248 (22%)]\tLoss: 0.509231\n",
            "Train Epoch: 5 [12800/29248 (44%)]\tLoss: 0.487201\n",
            "Train Epoch: 5 [19200/29248 (66%)]\tLoss: 0.515949\n",
            "Train Epoch: 5 [25600/29248 (88%)]\tLoss: 0.737941\n",
            "Train Epoch: 6 [0/29248 (0%)]\tLoss: 0.665532\n",
            "Train Epoch: 6 [6400/29248 (22%)]\tLoss: 0.502233\n",
            "Train Epoch: 6 [12800/29248 (44%)]\tLoss: 0.478719\n",
            "Train Epoch: 6 [19200/29248 (66%)]\tLoss: 0.505794\n",
            "Train Epoch: 6 [25600/29248 (88%)]\tLoss: 0.732067\n",
            "Train Epoch: 7 [0/29248 (0%)]\tLoss: 0.658173\n",
            "Train Epoch: 7 [6400/29248 (22%)]\tLoss: 0.494718\n",
            "Train Epoch: 7 [12800/29248 (44%)]\tLoss: 0.468176\n",
            "Train Epoch: 7 [19200/29248 (66%)]\tLoss: 0.499635\n",
            "Train Epoch: 7 [25600/29248 (88%)]\tLoss: 0.723527\n",
            "Train Epoch: 8 [0/29248 (0%)]\tLoss: 0.654077\n",
            "Train Epoch: 8 [6400/29248 (22%)]\tLoss: 0.486462\n",
            "Train Epoch: 8 [12800/29248 (44%)]\tLoss: 0.456710\n",
            "Train Epoch: 8 [19200/29248 (66%)]\tLoss: 0.491037\n",
            "Train Epoch: 8 [25600/29248 (88%)]\tLoss: 0.713569\n",
            "Train Epoch: 9 [0/29248 (0%)]\tLoss: 0.644415\n",
            "Train Epoch: 9 [6400/29248 (22%)]\tLoss: 0.477816\n",
            "Train Epoch: 9 [12800/29248 (44%)]\tLoss: 0.443651\n",
            "Train Epoch: 9 [19200/29248 (66%)]\tLoss: 0.484443\n",
            "Train Epoch: 9 [25600/29248 (88%)]\tLoss: 0.706673\n",
            "Train Epoch: 10 [0/29248 (0%)]\tLoss: 0.631454\n",
            "Train Epoch: 10 [6400/29248 (22%)]\tLoss: 0.468419\n",
            "Train Epoch: 10 [12800/29248 (44%)]\tLoss: 0.432559\n",
            "Train Epoch: 10 [19200/29248 (66%)]\tLoss: 0.476973\n",
            "Train Epoch: 10 [25600/29248 (88%)]\tLoss: 0.694488\n"
          ]
        }
      ],
      "source": [
        "#train data\n",
        "for iter in range (0,M):\n",
        "\n",
        "  globals()['model%s' % iter]=Net(torch)\n",
        "  optimizer = torch.optim.Adam(globals()['model%s' % iter].parameters(), lr=args.lr)\n",
        "  train_loader=0\n",
        "  train_loader=globals()['train_loader%s' % iter]\n",
        "  for epoch in range(1, args.epochs + 1):\n",
        "     train(args, globals()['model%s' % iter], train_loader, optimizer, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmfTPPawk5ap"
      },
      "outputs": [],
      "source": [
        "#test data\n",
        "def test(args, model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            output = F.log_softmax(output, dim=1)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHA6GYi1tocT",
        "outputId": "97caf6a4-b0e8-4718-9113-80401cee2faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.4900, Accuracy: 397/500 (79%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.4847, Accuracy: 391/500 (78%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for iter in range (0,M):\n",
        "     test(args, globals()['model%s' % iter], test_case_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebd6FhB2tt8B",
        "outputId": "34433ea7-89a7-456c-ddf1-5a3fbbfaa764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.Net object at 0x0000026E8FC2ECA0>\n",
            "<__main__.Net object at 0x0000026E8FC20EB0>\n"
          ]
        }
      ],
      "source": [
        "#secure evaluation \n",
        "import timeit\n",
        "start1 = timeit.default_timer()\n",
        "for iter in range (0,M):\n",
        "\n",
        "  #globals()['model%s' % iter].share(parties=[alice, bob, crypto_provider]) \n",
        "  print (globals()['model%s' % iter])\n",
        "  model_i = globals()['model%s' % iter]\n",
        "  enc_model = model_i.share(session) \n",
        "  globals()['enc_model%s' % iter] = enc_model\n",
        "  #model_i.share(parties=[alice, bob, crypto_provider]) \n",
        "stop1 = timeit.default_timer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRN2EIe99YvE",
        "outputId": "f4f34aa4-7bcf-47a3-d0ec-8aec24859417"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.23972300000002633"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop1-start1  #required time to model owner's secret share their model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG31OtRjtzyn"
      },
      "outputs": [],
      "source": [
        "def produce_probability(args, model, test_loader):\n",
        "    #model.eval()\n",
        "    n_correct_priv = 0\n",
        "    n_correct_sum = 0\n",
        "    n_total = 0\n",
        "    actuals = []\n",
        "    predictions = []\n",
        "    yhat=[]\n",
        "    k=0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader[0:500]:\n",
        "            output = model(data)\n",
        "            #mpc_model = model.share(session)\n",
        "            #output = mpc_model(data)\n",
        "            \n",
        "            #print(output.shape)\n",
        "            #pred = output.argmax(dim=1)\n",
        "            #print(pred.shape) \n",
        "            #n_correct_priv = pred.eq(target.view_as(pred))#.sum()\n",
        "            #out=n_correct_priv.copy().get().float_precision().long().item()\n",
        "            #print(out)\n",
        "            #n_total += args.test_batch_size\n",
        "            #pred = output.argmax(dim=1) \n",
        "            #n_correct_priv += pred.eq(target.view_as(pred)).sum()\n",
        "            #n_total += args.test_batch_size\n",
        "\n",
        "            #n_correct = n_correct_priv.copy().get().float_precision().long().item()\n",
        "            \n",
        "            \n",
        "            #outputs=torch.sum(output, dim=0)\n",
        "            \n",
        "\n",
        "            #yhat=[]\n",
        "            #for i in range(4):\n",
        "            #  z=0\n",
        "            #  #z=outputs[i].copy().get().float_precision().long().item()\n",
        "            #  z=outputs[i].copy().get().float_precision().long().item()\n",
        "              \n",
        "              \n",
        "              \n",
        "            #  yhat.append(z)\n",
        "\n",
        "            #yhat=np.clip(yhat, 0, 1)\n",
        "            #k=np.argmax(yhat)\n",
        "            #actuals.append(k)\n",
        "            \n",
        "\n",
        "            \n",
        "    \n",
        "            \n",
        "            plain_text_result = output.reconstruct()\n",
        "            print (plain_text_result)\n",
        "            yhat.append(plain_text_result)\n",
        "            #print(k)\n",
        "            k=k+1\n",
        "    \n",
        "        return yhat\n",
        "\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5n-CetdIc0R"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F6msDy0t3I3",
        "outputId": "2c561432-ec04-4437-8a5a-0bbbb3d99eb1"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "There is no current event loop in thread 'Thread-9'.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-59-3c2b62ee70ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#stop = timeit.default_timer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m Parallel(n_jobs=2, require='sharedmem')(\n\u001b[0m\u001b[0;32m     18\u001b[0m  delayed(training)(i) for i in range(0,M))\n\u001b[0;32m     19\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;31m# We capture the KeyboardInterrupt and reraise it as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-59-3c2b62ee70ff>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(iter)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#for iter in range(0,10):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0my_actual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproduce_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'enc_model%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprivate_new_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0my_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_actual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-57-80d486fbdeb7>\u001b[0m in \u001b[0;36mproduce_probability\u001b[1;34m(args, model, test_loader)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;31m#mpc_model = model.share(session)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m#output = mpc_model(data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\syft\\lib\\torch\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     ) -> Any:\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-50-7c4e4e6dcd92>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\sympc-0.5.0rc1.post0.dev105+g634396a-py3.8.egg\\sympc\\module\\nn\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mAn\u001b[0m \u001b[0mMPCTensor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mresults\u001b[0m \u001b[0mby\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \"\"\"\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\sympc-0.5.0rc1.post0.dev105+g634396a-py3.8.egg\\sympc\\tensor\\mpc_tensor.py\u001b[0m in \u001b[0;36mwrapper_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0m_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\sympc-0.5.0rc1.post0.dev105+g634396a-py3.8.egg\\sympc\\tensor\\mpc_tensor.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[0mMPCTensor\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mResult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__apply_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"matmul\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     def conv2d(\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\sympc-0.5.0rc1.post0.dev105+g634396a-py3.8.egg\\sympc\\tensor\\mpc_tensor.py\u001b[0m in \u001b[0;36m__apply_op\u001b[1;34m(self, y, op_str, kwargs_)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_private\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__apply_private_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__apply_public_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\sympc-0.5.0rc1.post0.dev105+g634396a-py3.8.egg\\sympc\\tensor\\mpc_tensor.py\u001b[0m in \u001b[0;36m__apply_private_op\u001b[1;34m(self, y, op_str, kwargs_)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshare_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mShareTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspdz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_master\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMPCTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\sympc-0.5.0rc1.post0.dev105+g634396a-py3.8.egg\\sympc\\protocol\\spdz\\spdz.py\u001b[0m in \u001b[0;36mmul_master\u001b[1;34m(x, y, op_str, kwargs_)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparallel_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspdz_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mEmptyPrimitiveStore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         CryptoPrimitiveProvider.generate_primitives(\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\site-packages\\sympc-0.5.0rc1.post0.dev105+g634396a-py3.8.egg\\sympc\\utils\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(args, kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mfutures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         with executor(\n",
            "\u001b[1;32mc:\\Miniconda\\lib\\asyncio\\events.py\u001b[0m in \u001b[0;36mget_event_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_local\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             raise RuntimeError('There is no current event loop in thread %r.'\n\u001b[0m\u001b[0;32m    640\u001b[0m                                % threading.current_thread().name)\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: There is no current event loop in thread 'Thread-9'."
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "def training(iter):\n",
        "#for iter in range(0,10):\n",
        "    y_actual=produce_probability(args,globals()['enc_model%s' % iter],private_new_loader)\n",
        "    y_array=np.array(y_actual)\n",
        "    y_probability=y_array.reshape(500,4)\n",
        "    import pandas as pd \n",
        "  #'y'+str(iter)=y_probability\n",
        "    pd.DataFrame(y_probability).to_csv('/content/gdrive/.....'+'y'+str(iter)+'.csv') #save inference files in your directory\n",
        "   #iter=iter+1\n",
        "  \n",
        "\n",
        "#stop = timeit.default_timer()\n",
        "\n",
        "## new code\n",
        "for i in range(0,M):\n",
        "    training(i)\n",
        "\n",
        "    \n",
        "#Parallel(n_jobs=2, require='sharedmem')(\n",
        "# delayed(training)(i) for i in range(0,M))\n",
        "#stop = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ueib9I-lDTH"
      },
      "outputs": [],
      "source": [
        "print('Time: ', stop - start) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOJZ-LOUuQ4N"
      },
      "outputs": [],
      "source": [
        "#compute label\n",
        "def label(my_list):\n",
        "  import numpy as np\n",
        "  my_array=np.array(my_list)\n",
        "  p=np.zeros(my_array.shape)\n",
        "  b=my_array.max(-1)\n",
        "  condition = my_array == b[..., np.newaxis]\n",
        "  c = np.where(condition, 1, 0)\n",
        "  final=np.multiply(c, my_array)\n",
        "  #my_sum=np.sum(final,axis=0)\n",
        "  labels=np.argmax(final, axis=1)\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD8qqEnAutM2"
      },
      "outputs": [],
      "source": [
        "#function for vote counting\n",
        "def vote(my_list):\n",
        "  import numpy as np\n",
        "  my_array=np.array(my_list)\n",
        "  p=np.zeros(my_array.shape)\n",
        "  b=my_array.max(-1)\n",
        "  condition = my_array == b[..., np.newaxis]\n",
        "  c = np.where(condition, 1, 0)\n",
        "  final=np.multiply(c, my_array)\n",
        "  #my_sum=np.sum(final,axis=0)\n",
        "  labels=np.argmax(final, axis=1)\n",
        "  return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3066Rp-ubot"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred=y_test[0:500]    #total prediction vector/actual prediction\n",
        "#y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbpRf-WSqKvo"
      },
      "outputs": [],
      "source": [
        "#df=pd.read_csv('y0.csv')\n",
        "#define vector of zeros\n",
        "df=np.zeros(500*4)\n",
        "df=df.reshape(500,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QLaHVrQq0HZ"
      },
      "outputs": [],
      "source": [
        "#call the saved prediction output from the drive\n",
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "from google.colab import drive \n",
        "import pandas as pd\n",
        "sum=np.zeros(500*4)\n",
        "sum=sum.reshape(500,4)\n",
        "for iter in range (0,10):\n",
        "  y=np.zeros(df.shape)\n",
        "  y=pd.read_csv('......../Hospitals10/'+'y'+str(iter)+'.csv')   #save your drive name where the inference vector are saved\n",
        "  #y=y_probability\n",
        "  y=y.drop(columns='Unnamed: 0')\n",
        "  yd=pd.DataFrame(y).to_numpy()\n",
        "  #yd=yd*10\n",
        "  yd=vote(yd)\n",
        "  sum=yd+sum\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print(stop-start)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afQ3MG6prYKb"
      },
      "outputs": [],
      "source": [
        "#create the labels\n",
        "lab=label(sum)\n",
        "sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVHXZAsOreGk"
      },
      "outputs": [],
      "source": [
        "#clear accuracy\n",
        "accuracy_score(y_pred,lab)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVd7kC_iyGSO"
      },
      "outputs": [],
      "source": [
        "#Client_acc_40_C=np.zeros(len(noise))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlxylUO8rhcD"
      },
      "outputs": [],
      "source": [
        "#Client_acc_40=np.zeros(len(noise))\n",
        "#Client_acc_20=np.zeros(len(noise))\n",
        "Client_acc_10=np.zeros(len(noise))   #compute accuracy for 10 number of model owners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owwMVJfd5AWR"
      },
      "outputs": [],
      "source": [
        "#add noise \n",
        "def add_noise_sum(noise,sum,experiment,ypred):\n",
        "  sum_s=sum\n",
        "  predt=np.zeros(experiment)\n",
        "  for i1 in range(experiment):\n",
        "    sum_s=np.zeros(sum.shape)\n",
        "    sum_f=sum+np.random.laplace(loc=0.0, scale=1/noise)\n",
        "    sum2=label(sum_f)\n",
        "    predt[i1]=accuracy_score(ypred,sum2)\n",
        "    #print(i)\n",
        "  pred=np.average(predt)\n",
        "  #print(predt)\n",
        "  #print(pred)\n",
        "  return pred\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO9L4uJbrtHY"
      },
      "outputs": [],
      "source": [
        "noise=[.01,.02,.03, .05,.1,.3,.5,.7,.9,1]  #noise\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "#Noise after Aggregation Method\n",
        "for i in range(0,len(noise)):\n",
        "                          sum_s=np.zeros(sum.shape)\n",
        "                 #sum2=np.zeros(sum1.shape)\n",
        "                 #predF=0\n",
        "                 #y_label=0\n",
        "                          sum_n=sum\n",
        "                          #sum_s=sum_n+np.random.laplace(loc=0.0, scale=1/noise[i])\n",
        "                          predF=add_noise_sum(noise[i],sum_n,50,y_pred)\n",
        "                          #print(sum_s)\n",
        "\n",
        "                          #sum2=label(sum_s)\n",
        "                          #print(sum2)\n",
        "                          #y_label=label(y_test)\n",
        "                          #predF=accuracy_score(y_pred,sum2)\n",
        "#predF=average_precision_score(y_test,sum2)\n",
        "#print(predF)\n",
        "                          Client_acc_10[i]=predF*100\n",
        "print(Client_acc_10)\n",
        "#print(Client_acc1)\n",
        "print(noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_52XdvNrruP-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "# plotting the points \n",
        "test1 = plt.figure()\n",
        "#plt.plot(noise, Client_acc_40, linestyle='--',marker='.',color='blue',label='Number of Model Owners=40',linewidth=1.2)  \n",
        "#plt.plot(noise, Client_acc_20,linestyle='--', marker='.',color='red',label='Number of Model Owners=20',linewidth=1.2)  \n",
        "plt.plot(noise, Client_acc_10, marker='.',color='black',label='Number of Model Owners=10',linewidth=1.2) \n",
        "# naming the x axis \n",
        "x=plt.xlabel('Privacy Budget, epsilon', fontsize='15') \n",
        "x.set_color(\"black\")\n",
        "# naming the y axis \n",
        "y=plt.ylabel('Inference Accuracy ',fontsize='15') \n",
        "y.set_color(\"black\")\n",
        "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
        "plt.rcParams[\"axes.linewidth\"] = 1\n",
        "plt.ylim((0,90))\n",
        "plt.xlim((0,1)) \n",
        "plt.xticks(np.arange(0, 1, .1)) \n",
        "plt.yticks(np.arange(0, 90, 10))\n",
        "plt.grid(b=None)\n",
        "#acc_final\n",
        "#plt.legend()\n",
        "\n",
        "plt.legend()\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "test1.show()\n",
        "test1.set_facecolor('white')\n",
        "test1.savefig('test1.pdf')\n",
        "#files.download('test1.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgWpCuBkXmur"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "# plotting the points \n",
        "test1 = plt.figure()\n",
        "plt.plot(noise, Client_acc_40,linestyle='--', marker='.',color='black',label='Model Owners Vote Count',linewidth=2) \n",
        "plt.plot(noise, Client_acc_40_C,linestyle='--', marker='.',color='red',label='Sum of Confidence Value',linewidth=1.2)  \n",
        "#plt.plot(noise, Client_acc_10,linestyle='--', marker='*',color='blue',label='Number of Model Owners=10',linewidth=1.2) \n",
        "# naming the x axis \n",
        "x=plt.xlabel('Privacy Budget, epsilon', fontsize='15') \n",
        "x.set_color(\"black\")\n",
        "# naming the y axis \n",
        "y=plt.ylabel('Inference Accuracy ',fontsize='15') \n",
        "y.set_color(\"black\")\n",
        "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
        "plt.rcParams[\"axes.linewidth\"] = 1\n",
        "plt.ylim((0,90))\n",
        "plt.xlim((0,1)) \n",
        "plt.xticks(np.arange(0, 1, .1)) \n",
        "plt.yticks(np.arange(0, 90, 10))\n",
        "plt.grid(b=None)\n",
        "#acc_final\n",
        "#plt.legend()\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "plt.legend(loc=4)\n",
        "test1.show()\n",
        "test1.set_facecolor('white')\n",
        "test1.savefig('test1.pdf')\n",
        "#files.download('test1.pdf')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Hospital_Stays_SMPC_DP_upload.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}